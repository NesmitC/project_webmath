# app/assistant.py

import os
import re
import requests
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
from langchain.docstore.document import Document
from langchain.text_splitter import RecursiveCharacterTextSplitter
import pandas as pd

# --- –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ ---
_embeddings = None
_db = None
_retriever = None
_hard_cases = {}
_VECTOR_STORE_PATH = "faiss_index_webmath"

# --- –ó–∞–≥—Ä—É–∑–∫–∞ —Å–ª–æ–∂–Ω—ã—Ö —Å–ª—É—á–∞–µ–≤ ---
CSV_URL = "https://docs.google.com/spreadsheets/d/1dQxvFLhajJOvdCM2rdqTMeJhy49cOVBQKfRH_3i0IRw/export?format=csv&gid=0"

def load_hard_cases():
    global _hard_cases
    try:
        df = pd.read_csv(CSV_URL)
        print("‚úÖ –¢–∞–±–ª–∏—Ü–∞ —Å–ª–æ–∂–Ω—ã—Ö —Å–ª—É—á–∞–µ–≤ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
        for _, row in df.iterrows():
            triggers = str(row["trigger"]).lower().split("|")
            for trigger in triggers:
                trigger = trigger.strip()
                if trigger:
                    _hard_cases[trigger] = {
                        "answer": row["answer"],
                        "rule": row["rule"]
                    }
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ CSV: {e}")

# --- –ó–∞–≥—Ä—É–∑–∫–∞ —Ç–µ–∫—Å—Ç–∞ –∏–∑ Google Docs ---
def load_document_text(url: str) -> str:
    url = url.strip().split('/edit')[0]
    match_ = re.search(r'/document/d/([a-zA-Z0-9-_]+)', url)
    if not match_:
        raise ValueError('Invalid Google Docs URL')
    doc_id = match_.group(1).strip()
    export_url = f'https://docs.google.com/document/d/{doc_id}/export?format=txt'
    response = requests.get(export_url)
    response.raise_for_status()
    return response.text

# --- –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∑–∞–ø—Ä–æ—Å–µ ---
def get_retriever():
    global _embeddings, _db, _retriever
    if _retriever is not None:
        return _retriever

    print("üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤...")

    _embeddings = HuggingFaceEmbeddings(
        model_name="sentence-transformers/all-MiniLM-L6-v2"
    )

    if os.path.exists(_VECTOR_STORE_PATH):
        print("üìÇ –ó–∞–≥—Ä—É–∑–∫–∞ —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω–æ–≥–æ FAISS-–∏–Ω–¥–µ–∫—Å–∞...")
        _db = FAISS.load_local(
            _VECTOR_STORE_PATH,
            _embeddings,
            allow_dangerous_deserialization=True
        )
    else:
        print("üÜï –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–≥–æ FAISS-–∏–Ω–¥–µ–∫—Å–∞...")

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –±–∞–∑—É –∑–Ω–∞–Ω–∏–π
        raw_data = load_document_text('https://docs.google.com/document/d/1CcW-xOVPIPUZaiMxJsl5SmCKyebfhIYwmkz1ONH_neI/edit?usp=sharing')

        # –î–æ–±–∞–≤–ª—è–µ–º –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ
        definition = """
        ## –ß—Ç–æ —Ç–∞–∫–æ–µ —Å–ø—Ä—è–∂–µ–Ω–∏–µ?
        –°–ø—Ä—è–∂–µ–Ω–∏–µ ‚Äî —ç—Ç–æ –∏–∑–º–µ–Ω–µ–Ω–∏–µ –≥–ª–∞–≥–æ–ª–æ–≤ –ø–æ –ª–∏—Ü–∞–º –∏ —á–∏—Å–ª–∞–º –≤ –∏–∑—ä—è–≤–∏—Ç–µ–ª—å–Ω–æ–º –Ω–∞–∫–ª–æ–Ω–µ–Ω–∏–∏. –í —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ –¥–≤–∞ —Å–ø—Ä—è–∂–µ–Ω–∏—è: –ø–µ—Ä–≤–æ–µ –∏ –≤—Ç–æ—Ä–æ–µ.
        """
        cleaned_data = definition + "\n\n" + raw_data

        # –†–∞–∑–±–∏–≤–∫–∞
        text_splitter = RecursiveCharacterTextSplitter(chunk_size=250, chunk_overlap=50)
        texts = text_splitter.split_text(cleaned_data)
        docs = [Document(page_content=txt) for txt in texts]

        # –°–æ–∑–¥–∞–Ω–∏–µ –±–∞–∑—ã
        _db = FAISS.from_documents(docs, _embeddings)
        _db.save_local(_VECTOR_STORE_PATH)

    _retriever = _db.as_retriever(k=1)
    print("‚úÖ –ú–æ–¥–µ–ª—å –∏ –±–∞–∑–∞ –∑–Ω–∞–Ω–∏–π –≥–æ—Ç–æ–≤—ã.")
    return _retriever

# --- DeepSeek API ---
DEEPSEEK_API_KEY = os.getenv("DEEPSEEK_API_KEY")
if not DEEPSEEK_API_KEY:
    raise EnvironmentError("DEEPSEEK_API_KEY –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞")

DEEPSEEK_URL = "https://api.deepseek.com/v1/chat/completions"
HEADERS = {
    "Authorization": f"Bearer {DEEPSEEK_API_KEY}",
    "Content-Type": "application/json"
}

def deepseek_complete(prompt: str) -> str:
    payload = {
        "model": "deepseek-chat",
        "messages": [{"role": "user", "content": prompt}],
        "temperature": 0.1,
        "max_tokens": 200
    }
    try:
        response = requests.post(DEEPSEEK_URL, json=payload, headers=HEADERS)
        response.raise_for_status()
        return response.json()["choices"][0]["message"]["content"].strip()
    except Exception as e:
        return f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ DeepSeek: {str(e)}"

# --- –û–°–ù–û–í–ù–ê–Ø –§–£–ù–ö–¶–ò–Ø ---
def ask_teacher(question: str):
    question = question.strip()
    if not question:
        return "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –∑–∞–¥–∞–π—Ç–µ –≤–æ–ø—Ä–æ—Å."

    # 1. –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–ª–æ–∂–Ω—ã—Ö —Å–ª—É—á–∞–µ–≤
    q_lower = question.lower()
    for trigger in _hard_cases:
        if trigger in q_lower:
            case = _hard_cases[trigger]
            answer = case["answer"]
            if case["rule"]:
                answer += f" –ü—Ä–∞–≤–∏–ª–æ: {case['rule']}"
            return answer

    # 2. –ü–æ–∏—Å–∫ –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π
    retriever = get_retriever()
    relevant_docs = retriever.get_relevant_documents(question)
    context = "\n\n".join([doc.page_content for doc in relevant_docs])

    prompt = f"""
–¢—ã ‚Äî –Ω–µ–π—Ä–æ—Å–æ—Ç—Ä—É–¥–Ω–∏–∫-—É—á–∏—Ç–µ–ª—å —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞. –û—Ç–≤–µ—á–∞–π –∫—Ä–∞—Ç–∫–æ, —Ç–æ—á–Ω–æ –∏ —Ç–æ–ª—å–∫–æ –ø–æ —Ñ–∞–∫—Ç–∞–º –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞.

–ü—Ä–∞–≤–∏–ª–∞:
1. –û—Ç–≤–µ—á–∞–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ.
2. –û—Ç–≤–µ—Ç ‚Äî 1‚Äì2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è, –±–µ–∑ –ª–∏—à–Ω–∏—Ö —Å–ª–æ–≤.
3. –ù–µ —É–ø–æ–º–∏–Ω–∞–π "—Ä–∞–∑–¥–µ–ª", "—á–∞–Ω–∫", "–∑–∞–≥–æ–ª–æ–≤–æ–∫".
4. –ï—Å–ª–∏ –≤–æ–ø—Ä–æ—Å —Å –æ—à–∏–±–∫–æ–π ‚Äî –æ—Ç–≤–µ—Ç—å: ¬´–ü—Ä–∞–≤–∏–ª—å–Ω–æ: ...¬ª
5. –ï—Å–ª–∏ –≤–æ–ø—Ä–æ—Å –Ω–µ—è—Å–µ–Ω ‚Äî –ø–æ–ø—Ä–æ—Å–∏ —É—Ç–æ—á–Ω–∏—Ç—å.
6. –ï—Å–ª–∏ –æ—Ç–≤–µ—Ç–∞ –Ω–µ—Ç ‚Äî —Å–∫–∞–∂–∏: ¬´–í–∞—à –≤–æ–ø—Ä–æ—Å –±—É–¥–µ—Ç –ø–µ—Ä–µ–¥–∞–Ω –º–µ—Ç–æ–¥–∏—á–µ—Å–∫–æ–π —Å–ª—É–∂–±–µ.¬ª

–ö–æ–Ω—Ç–µ–∫—Å—Ç:
{context}

–í–æ–ø—Ä–æ—Å: {question}

–û—Ç–≤–µ—Ç:
"""

    return deepseek_complete(prompt)

# --- –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –ø—Ä–∏ –∏–º–ø–æ—Ä—Ç–µ ---
load_hard_cases()